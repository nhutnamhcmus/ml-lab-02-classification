{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Plant_Pathology_Modeling_PyTorch_V2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10b8fe0b1045486f9b18e2b9266f80ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_349ee815416d44c1b185cf30b3debe35",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee582b54357d49f09cb1db063dfc4f33",
              "IPY_MODEL_3f2705205ebb423580141f25722180ab"
            ]
          }
        },
        "349ee815416d44c1b185cf30b3debe35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee582b54357d49f09cb1db063dfc4f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3e888b265af54379a935136bd45fbb31",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 122410125,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 122410125,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_718caa357a904179b46265781990cdc9"
          }
        },
        "3f2705205ebb423580141f25722180ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c2849016e69d4393b409fdb15a63a1f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 117M/117M [00:01&lt;00:00, 94.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef88674f3c924a62b1920abf1e139f11"
          }
        },
        "3e888b265af54379a935136bd45fbb31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "718caa357a904179b46265781990cdc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2849016e69d4393b409fdb15a63a1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef88674f3c924a62b1920abf1e139f11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKkkDxBncRLi"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfWZjy-ycTZr",
        "outputId": "c649a08c-f1fe-4130-cd78-027c0fc58b9c"
      },
      "source": [
        "!pip install pretrainedmodels\n",
        "!pip install albumentations==0.4.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pretrainedmodels\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 15.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (0.9.1+cu101)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->pretrainedmodels) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pretrainedmodels) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->pretrainedmodels) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels) (1.15.0)\n",
            "Building wheels for collected packages: pretrainedmodels\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp37-none-any.whl size=60963 sha256=740e0c3031a52ba990557b5b739f14f7c5f2594740797761ec1fe96be28da652\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
            "Successfully built pretrainedmodels\n",
            "Installing collected packages: munch, pretrainedmodels\n",
            "Successfully installed munch-2.5.0 pretrainedmodels-0.7.4\n",
            "Collecting albumentations==0.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/40/a343ecacc7e22fe52ab9a16b84dc6165ba05ee17e3729adeb3e2ffa2b37b/albumentations-0.4.5.tar.gz (116kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.5) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.5) (1.4.1)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.5) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.5) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (0.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.15.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (7.1.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.5.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (0.10.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (4.4.2)\n",
            "Building wheels for collected packages: albumentations, imgaug\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.5-cp37-none-any.whl size=64378 sha256=c8805fe2b04b74917b53263f73b07d55dc02ba8101a4917d8141a7f6dbd87129\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/a0/61/e50f93165a5ec7e7f5d65064e513239505bc4c06d2289557d3\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp37-none-any.whl size=654019 sha256=4e792f8cdd5e697b4353bf830f5b35eefc5f1cbc9649ec403515bb7fe2b57ce4\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built albumentations imgaug\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.5 imgaug-0.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43_nXTpWTODd",
        "outputId": "2c504be0-2fe0-4582-a757-62acf9ca051b"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 34.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s55SiYbUHRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f179d69e-92d1-47bd-f3c3-59c2b43576ef"
      },
      "source": [
        "# install dependencies for TPU\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  5116  100  5116    0     0  35527      0 --:--:-- --:--:-- --:--:-- 35527\n",
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200515 ...\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Collecting google-api-python-client==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.30.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.26.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client) (4.7.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (56.1.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.2.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (20.9)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.12.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.53.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.4.7)\n",
            "Uninstalling torch-1.8.1+cu101:\n",
            "\u001b[31mERROR: earthengine-api 0.1.266 has requirement google-api-python-client<2,>=1.12.1, but you'll have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
            "  Found existing installation: google-api-python-client 1.12.8\n",
            "    Uninstalling google-api-python-client-1.12.8:\n",
            "      Successfully uninstalled google-api-python-client-1.12.8\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
            "Done updating TPU runtime\n",
            "  Successfully uninstalled torch-1.8.1+cu101\n",
            "Uninstalling torchvision-0.9.1+cu101:\n",
            "  Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\n",
            "- [1 files][ 91.0 MiB/ 91.0 MiB]                                                \n",
            "Operation completed over 1 objects/91.0 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\n",
            "\\ [1 files][119.5 MiB/119.5 MiB]                                                \n",
            "Operation completed over 1 objects/119.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\n",
            "/ [1 files][  2.3 MiB/  2.3 MiB]                                                \n",
            "Operation completed over 1 objects/2.3 MiB.                                      \n",
            "Processing ./torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==nightly+20200515) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==nightly+20200515) (0.16.0)\n",
            "\u001b[31mERROR: pretrainedmodels 0.7.4 requires torchvision, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.6.0a0+bf2bbd9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.6.0a0+bf2bbd9\n",
            "Processing ./torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+2b2085a\n",
            "Processing ./torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20200515) (1.6.0a0+bf2bbd9)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20200515) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20200515) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->torchvision==nightly+20200515) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+a6073f0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (365 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 160706 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLqA7wTMclHa"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbXktwalcnUi",
        "outputId": "bae28478-8656-4d4f-eae9-a75904ff3727"
      },
      "source": [
        "# Link for image jpg type: https://drive.google.com/file/d/1jfkX_NXF8shxyWZCxJkzsLPDr4ebvdOP/view?usp=sharing\n",
        "# Link for image npy type: https://drive.google.com/file/d/1NXYzfPWcvyZOBYHAlmBISLb6iRge_KXf/view?usp=sharing\n",
        "!pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1NXYzfPWcvyZOBYHAlmBISLb6iRge_KXf\n",
        "!unzip -q plant-pathology-2020-fgvc7-npy.zip -d /content/plant-pathology-2020-fgvc7-npy\n",
        "!rm plant-pathology-2020-fgvc7-npy.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NXYzfPWcvyZOBYHAlmBISLb6iRge_KXf\n",
            "To: /content/plant-pathology-2020-fgvc7-npy.zip\n",
            "2.09GB [00:20, 99.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdwPVePFcURK"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIFU13m2cTuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0458fa1-1799-4fc1-a3e8-c5f9db75694c"
      },
      "source": [
        "# Import os\n",
        "import os\n",
        "\n",
        "# Import libraries for data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Import libries for data agumentations: albumentations\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensor\n",
        "from albumentations import Rotate \n",
        "import cv2 as cv\n",
        "\n",
        "# Import Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Import pretrainmodels\n",
        "import pretrainedmodels\n",
        "\n",
        "# Import transformers\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "from transformers import AdamW\n",
        "\n",
        "# Import metrics for model evaluation\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Import libraries for data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import tqdm.notebook for loading visualization\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings  \n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('__call__', <function LevelMapper.__call__ at 0x7f7ae1be0320>), ('__init__', <function LevelMapper.__init__ at 0x7f7ae1be0290>)]\n",
            "[('__call__', <function BalancedPositiveNegativeSampler.__call__ at 0x7f7ae1b28a70>), ('__init__', <function BalancedPositiveNegativeSampler.__init__ at 0x7f7ae1b289e0>)]\n",
            "[('__init__', <function BoxCoder.__init__ at 0x7f7ae1abb290>), ('decode', <function BoxCoder.decode at 0x7f7ae1abb440>), ('decode_single', <function BoxCoder.decode_single at 0x7f7ae1abb4d0>), ('encode', <function BoxCoder.encode at 0x7f7ae1abb320>), ('encode_single', <function BoxCoder.encode_single at 0x7f7ae1abb3b0>)]\n",
            "[('__call__', <function Matcher.__call__ at 0x7f7ae1abb5f0>), ('__init__', <function Matcher.__init__ at 0x7f7ae1aaff80>), ('set_low_quality_matches_', <function Matcher.set_low_quality_matches_ at 0x7f7ae1abb170>)]\n",
            "[('__init__', <function ImageList.__init__ at 0x7f7ae1b288c0>), ('to', <function ImageList.to at 0x7f7ae1abb710>)]\n",
            "[('__init__', <function Timebase.__init__ at 0x7f7ae1955e60>)]\n",
            "[('__init__', <function VideoMetaData.__init__ at 0x7f7ae1959dd0>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk2CNZMxUMHx"
      },
      "source": [
        "# Import for TPU configuration\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97RdvLx5cb5U"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykJyJqsOchZi"
      },
      "source": [
        "# Configuration path\n",
        "\n",
        "# Data folder\n",
        "IMAGES_PATH = '/content/plant-pathology-2020-fgvc7-npy/plant-pathology-2020-fgvc7-npy/images/'\n",
        "\n",
        "# Sample submission csv\n",
        "SAMPLE_SUBMISSION = '/content/plant-pathology-2020-fgvc7-npy/plant-pathology-2020-fgvc7-npy/sample_submission.csv'\n",
        "\n",
        "# Train, test data path\n",
        "TRAIN_DATA = '/content/plant-pathology-2020-fgvc7-npy/plant-pathology-2020-fgvc7-npy/train.csv'\n",
        "TEST_DATA = '/content/plant-pathology-2020-fgvc7-npy/plant-pathology-2020-fgvc7-npy/test.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6F_u-5Cce9b"
      },
      "source": [
        "# Configuration for training workflow\n",
        "SEED = 1234\n",
        "N_FOLDS = 5\n",
        "N_EPOCHS = 5\n",
        "BATCH_SIZE = 2\n",
        "SIZE = 512\n",
        "IMG_SHAPE = (1365, 2048, 3)\n",
        "lr = 8e-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYd2dPD_cuuz"
      },
      "source": [
        "submission_df = pd.read_csv(SAMPLE_SUBMISSION)\n",
        "df_train = pd.read_csv(TRAIN_DATA)\n",
        "df_test = pd.read_csv(TEST_DATA)\n",
        "\n",
        "def get_image_path(filename):\n",
        "    return (IMAGES_PATH + filename + '.jpg')\n",
        "\n",
        "#df_train['image_path'] = df_train['image_id'].apply(get_image_path)\n",
        "#df_test['image_path'] = df_test['image_id'].apply(get_image_path)\n",
        "#rain_labels = df_train.loc[:, 'healthy':'scab']\n",
        "#train_paths = df_train.image_path\n",
        "#test_paths = df_test.image_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "369V7CCgc97y",
        "outputId": "93f2c5b9-425a-4d75-f403-f0e7836c3e91"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>healthy</th>\n",
              "      <th>multiple_diseases</th>\n",
              "      <th>rust</th>\n",
              "      <th>scab</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Train_0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Train_1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Train_2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Train_3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Train_4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_id  healthy  multiple_diseases  rust  scab\n",
              "0  Train_0        0                  0     0     1\n",
              "1  Train_1        0                  1     0     0\n",
              "2  Train_2        1                  0     0     0\n",
              "3  Train_3        0                  0     1     0\n",
              "4  Train_4        1                  0     0     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FxDcvKDpc_Q3",
        "outputId": "d7f3497a-9db2-4553-f58a-ef6f42c3c824"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Test_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Test_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Test_4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_id\n",
              "0   Test_0\n",
              "1   Test_1\n",
              "2   Test_2\n",
              "3   Test_3\n",
              "4   Test_4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Y2OakmJKdARQ",
        "outputId": "e79a2431-0d16-46ea-eb9e-25744cb4e577"
      },
      "source": [
        "submission_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>healthy</th>\n",
              "      <th>multiple_diseases</th>\n",
              "      <th>rust</th>\n",
              "      <th>scab</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Test_0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test_1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test_2</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Test_3</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Test_4</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_id  healthy  multiple_diseases  rust  scab\n",
              "0   Test_0     0.25               0.25  0.25  0.25\n",
              "1   Test_1     0.25               0.25  0.25  0.25\n",
              "2   Test_2     0.25               0.25  0.25  0.25\n",
              "3   Test_3     0.25               0.25  0.25  0.25\n",
              "4   Test_4     0.25               0.25  0.25  0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM4US6YxcxPB",
        "outputId": "e7d47535-498c-48a5-e476-c889f3907f57"
      },
      "source": [
        "# for GPU\n",
        "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device\n",
        "\n",
        "\n",
        "# for TPU\n",
        "device = xm.xla_device()\n",
        "torch.set_default_tensor_type('torch.FloatTensor')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='xla', index=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDNP5ismc0oy"
      },
      "source": [
        "# Define Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvU6tJQzc0AK"
      },
      "source": [
        "class PlantDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, df, transforms=None):\n",
        "        self.df = df\n",
        "        self.transforms=transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # Solution 01: Read from raw image\n",
        "        # image_src = IMAGES_PATH + self.df.loc[idx, 'image_id'] + '.jpg'\n",
        "\n",
        "        # Solution 02: Read from npy file, we convert all images in images folder from .jpg to .npy\n",
        "        image = np.load(IMAGES_PATH + self.df.loc[idx, 'image_id'] + '.npy')\n",
        "\n",
        "        # print(image_src)\n",
        "        # image = cv.imread(image_src, cv.IMREAD_COLOR)\n",
        "        if image.shape != IMG_SHAPE:\n",
        "            image = image.transpose(1, 0, 2)\n",
        "        # image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "        labels = self.df.loc[idx, ['healthy', 'multiple_diseases', 'rust', 'scab']].values\n",
        "        labels = torch.from_numpy(labels.astype(np.int8))\n",
        "        labels = labels.unsqueeze(-1)\n",
        "        \n",
        "        if self.transforms:\n",
        "            transformed = self.transforms(image=image)\n",
        "            image = transformed['image']\n",
        "\n",
        "        return image, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esLtEbezdDZC"
      },
      "source": [
        "# Data Agumentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msgqAFO6dED5"
      },
      "source": [
        "# Train transformation\n",
        "transforms_train = A.Compose([\n",
        "        A.RandomResizedCrop(height=SIZE, width=SIZE, p=1.0),\n",
        "        A.OneOf([A.RandomBrightness(limit=0.1, p=1), A.RandomContrast(limit=0.1, p=1)]),\n",
        "            A.OneOf([A.MotionBlur(blur_limit=3), A.MedianBlur(blur_limit=3), A.GaussianBlur(blur_limit=3)], p=0.5),\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.ShiftScaleRotate(\n",
        "                shift_limit=0.2,\n",
        "                scale_limit=0.2,\n",
        "                rotate_limit=20,\n",
        "                interpolation=cv.INTER_LINEAR,\n",
        "                border_mode=cv.BORDER_REFLECT_101,\n",
        "                p=1,\n",
        "            ),\n",
        "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n",
        "             A.pytorch.ToTensorV2(p=1.0),\n",
        "    ], p=1.0)\n",
        "\n",
        "# Validation transformation\n",
        "transforms_valid = A.Compose([\n",
        "    A.Resize(height=SIZE, width=SIZE, p=1.0),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n",
        "    A.pytorch.ToTensorV2(p=1.0),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eHZp--0dIIO"
      },
      "source": [
        "# StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiqNaKMydIz5"
      },
      "source": [
        "# Get label from df_train\n",
        "train_labels = df_train.iloc[:, 1:].values\n",
        "train_y = train_labels[:, 2] + train_labels[:, 3] * 2 + train_labels[:, 1] * 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwVVJ1iMdPvJ"
      },
      "source": [
        "folds = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "oof_preds = np.zeros((df_train.shape[0], 4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrzMljEpdYAl"
      },
      "source": [
        "# PretrainedModels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr-rJ2BeTk2b"
      },
      "source": [
        "## Define cross entropy loss one hot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raG3EUjbd-Ix"
      },
      "source": [
        "# define cross entropy loss one hot\n",
        "class CrossEntropyLossOneHot(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CrossEntropyLossOneHot, self).__init__()\n",
        "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    def forward(self, preds, labels):\n",
        "        return torch.mean(torch.sum(-labels * self.log_softmax(preds), -1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kN8CFTDTp-c"
      },
      "source": [
        "## Define dense cross entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NR0vcgeR3Rf"
      },
      "source": [
        "# define dense cross entropy\n",
        "class DenseCrossEntropy(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DenseCrossEntropy, self).__init__()\n",
        "        \n",
        "        \n",
        "    def forward(self, logits, labels):\n",
        "        logits = logits.float()\n",
        "        labels = labels.float()\n",
        "        \n",
        "        logprobs = F.log_softmax(logits, dim=-1)\n",
        "        \n",
        "        loss = -labels * logprobs\n",
        "        loss = loss.sum(-1)\n",
        "\n",
        "        return loss.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbH4CiP5Tut0"
      },
      "source": [
        "## Define plant model with ResNet34"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FnEeTbtdYWy"
      },
      "source": [
        "# define plant model with ResNet\n",
        "class PlantModel(nn.Module):\n",
        "    # define init function\n",
        "    def __init__(self, num_classes=4):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.backbone = torchvision.models.resnet34(pretrained=True)\n",
        "        \n",
        "        in_features = self.backbone.fc.in_features\n",
        "\n",
        "        self.logit = nn.Linear(in_features, num_classes)\n",
        "    # define forward function\n",
        "    def forward(self, x):\n",
        "        batch_size, C, H, W = x.shape\n",
        "        \n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "\n",
        "        x = self.backbone.layer1(x)\n",
        "        x = self.backbone.layer2(x)\n",
        "        x = self.backbone.layer3(x)\n",
        "        x = self.backbone.layer4(x)\n",
        "        \n",
        "        x = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n",
        "        x = F.dropout(x, 0.25, self.training)\n",
        "\n",
        "        x = self.logit(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBzcQ2_3de53"
      },
      "source": [
        "# Train for StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X7VgeKPdcsR"
      },
      "source": [
        "def train_one_fold(i_fold, model, criterion, optimizer, lr_scheduler, dataloader_train, dataloader_valid):\n",
        "    \n",
        "    train_fold_results = []\n",
        "\n",
        "    for epoch in range(N_EPOCHS):\n",
        "        # print information\n",
        "        print('  Epoch {}/{}'.format(epoch + 1, N_EPOCHS))\n",
        "        print('  ' + ('-' * 20))\n",
        "        os.system(f'echo \\\"  Epoch {epoch}\\\"')\n",
        "\n",
        "        # call model\n",
        "        model.train()\n",
        "        tr_loss = 0\n",
        "\n",
        "        # looping\n",
        "        for step, batch in enumerate(dataloader_train):\n",
        "            # data preparation\n",
        "            images = batch[0].to(device)\n",
        "            labels = batch[1].to(device)\n",
        "          \n",
        "            # forward pass and calculate loss\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels.squeeze(-1))\n",
        "\n",
        "            # backward pass           \n",
        "            loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            \n",
        "            # updates\n",
        "            # for TPU\n",
        "            xm.optimizer_step(optimizer, barrier=True)\n",
        "\n",
        "            # for GPU\n",
        "            #optimizer.step()\n",
        "            \n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Validate\n",
        "        model.eval()\n",
        "        \n",
        "        # init validation loss, predicted and labels\n",
        "        val_loss = 0\n",
        "        val_preds = None\n",
        "        val_labels = None\n",
        "\n",
        "        for step, batch in enumerate(dataloader_valid):\n",
        "            # data preparation\n",
        "            images = batch[0].to(device)\n",
        "            labels = batch[1].to(device)\n",
        "\n",
        "            # labels preparation\n",
        "            if val_labels is None:\n",
        "                val_labels = labels.clone().squeeze(-1)\n",
        "            else:\n",
        "                val_labels = torch.cat((val_labels, labels.squeeze(-1)), dim=0)\n",
        "\n",
        "            \n",
        "            # disable torch grad to calculating normally\n",
        "            with torch.no_grad():\n",
        "                # calculate the output\n",
        "                outputs = model(batch[0].to(device))\n",
        "\n",
        "                # calculate the loss value\n",
        "                loss = criterion(outputs, labels.squeeze(-1))\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                # predict with softmax activation function\n",
        "                preds = torch.softmax(outputs, dim=1).data.cpu()\n",
        "                #preds = torch.softmax(outputs, dim=1).detach().cpu().numpy()\n",
        "\n",
        "                \n",
        "                if val_preds is None:\n",
        "                    val_preds = preds\n",
        "                else:\n",
        "                    val_preds = torch.cat((val_preds, preds), dim=0)\n",
        "           \n",
        "        # if train mode\n",
        "        lr_scheduler.step(tr_loss)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            train_loss = tr_loss / len(dataloader_train)\n",
        "            valid_loss = val_loss / len(dataloader_valid)\n",
        "            valid_score =  roc_auc_score(val_labels.view(-1).cpu(), val_preds.view(-1).cpu(), average='macro')\n",
        "        # print information\n",
        "        if epoch % 1 == 0:\n",
        "          print(f'Fold {i_fold + 1} Epoch {epoch + 1}: train_loss={train_loss:.8f}, valid_loss={valid_loss:.8f}, acc={valid_score:.8f}')\n",
        "        train_fold_results.append({\n",
        "            'fold': i_fold,\n",
        "            'epoch': epoch,\n",
        "            'train_loss': train_loss,\n",
        "            'valid_loss': valid_loss,\n",
        "            'valid_score': valid_score,\n",
        "        })\n",
        "\n",
        "    return val_preds, train_fold_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3X0tYdeT7UU"
      },
      "source": [
        "## Prepare submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-hCfV3OdjOC"
      },
      "source": [
        "submission_df.iloc[:, 1:] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFk3PboUUBTa"
      },
      "source": [
        "## Dataset test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAICQHG5doFK"
      },
      "source": [
        "dataset_test = PlantDataset(df=submission_df, transforms=transforms_valid)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loFl8eOhUHB2"
      },
      "source": [
        "# Init model: EfficientNetB5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XwCDBJIQNQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c940af27-5497-42dd-ea7a-ec975d379188"
      },
      "source": [
        "# EfficientNetB5\n",
        "# B5 is the largest EfficientNet variant that fits in GPU memory with batch size 8.\n",
        "!pip install efficientnet_pytorch\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/a0/dd40b50aebf0028054b6b35062948da01123d7be38d08b6b1e5435df6363/efficientnet_pytorch-0.7.1.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.6.0a0+bf2bbd9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (1.19.5)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-cp37-none-any.whl size=16443 sha256=1d8cb49cc99bb2d82c6786091b0ec29efaef407d44b124d20f5f6034d822627f\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/27/aa/c46d23c4e8cc72d41283862b1437e0b3ad318417e8ed7d5921\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oShA1QELQaPn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "10b8fe0b1045486f9b18e2b9266f80ff",
            "349ee815416d44c1b185cf30b3debe35",
            "ee582b54357d49f09cb1db063dfc4f33",
            "3f2705205ebb423580141f25722180ab",
            "3e888b265af54379a935136bd45fbb31",
            "718caa357a904179b46265781990cdc9",
            "c2849016e69d4393b409fdb15a63a1f3",
            "ef88674f3c924a62b1920abf1e139f11"
          ]
        },
        "outputId": "0f61019e-3681-4894-bec2-098447c3c26e"
      },
      "source": [
        "model = EfficientNet.from_pretrained('efficientnet-b5')\n",
        "\n",
        "num_ftrs = model._fc.in_features\n",
        "model._fc = nn.Sequential(nn.Linear(num_ftrs,1000,bias=True),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Dropout(p=0.5),\n",
        "                          nn.Linear(1000,4, bias = True))\n",
        "\n",
        "model.to(device)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b5-b6417697.pth\" to /root/.cache/torch/checkpoints/efficientnet-b5-b6417697.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10b8fe0b1045486f9b18e2b9266f80ff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=122410125.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded pretrained weights for efficientnet-b5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (_conv_stem): Conv2dStaticSamePadding(\n",
              "    3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "  )\n",
              "  (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_blocks): ModuleList(\n",
              "    (0): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (1): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (2): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (3): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (4): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (5): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (6): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (7): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(3, 3), stride=(1, 1), groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (8): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(5, 5), stride=[2, 2], groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (9): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (10): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (11): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (12): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        384, 384, kernel_size=(5, 5), stride=(1, 1), groups=384, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (13): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        384, 384, kernel_size=(3, 3), stride=[2, 2], groups=384, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        384, 16, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        16, 384, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (14): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (15): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (16): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (17): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (18): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (19): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        768, 768, kernel_size=(3, 3), stride=(1, 1), groups=768, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(128, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (20): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        768, 768, kernel_size=(5, 5), stride=[1, 1], groups=768, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(768, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        768, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        32, 768, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        768, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (21): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (22): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (23): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (24): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (25): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (26): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1056, 1056, kernel_size=(5, 5), stride=(1, 1), groups=1056, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(176, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (27): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1056, 1056, kernel_size=(5, 5), stride=[2, 2], groups=1056, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1056, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1056, 44, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        44, 1056, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (28): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (29): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (30): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (31): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (32): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (33): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (34): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (35): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(5, 5), stride=(1, 1), groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (36): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1824, 1824, kernel_size=(3, 3), stride=[1, 1], groups=1824, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1824, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1824, 76, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        76, 1824, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (37): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        3072, 3072, kernel_size=(3, 3), stride=(1, 1), groups=3072, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        3072, 128, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        128, 3072, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (38): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        3072, 3072, kernel_size=(3, 3), stride=(1, 1), groups=3072, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(3072, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        3072, 128, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        128, 3072, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(512, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "  )\n",
              "  (_conv_head): Conv2dStaticSamePadding(\n",
              "    512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "    (static_padding): Identity()\n",
              "  )\n",
              "  (_bn1): BatchNorm2d(2048, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "  (_dropout): Dropout(p=0.4, inplace=False)\n",
              "  (_fc): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=1000, out_features=4, bias=True)\n",
              "  )\n",
              "  (_swish): MemoryEfficientSwish()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7ci_PSRUPS9"
      },
      "source": [
        "# Init model: ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "cg1-pvxUgmAe",
        "outputId": "94c11b38-d8f1-428b-caa1-057ad9731af6"
      },
      "source": [
        "\"\"\"\n",
        "# Download pretrained weights.\n",
        "# model = PlantModel(num_classes=4)\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# print number of features\n",
        "num_features = model.fc.in_features\n",
        "print(num_features)\n",
        "\n",
        "\n",
        "# custome layers\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(512),\n",
        "    nn.Dropout(0.5),\n",
        "    \n",
        "    nn.Linear(512, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(256),\n",
        "    nn.Dropout(0.5),\n",
        "    \n",
        "    nn.Linear(256, 4))\n",
        "\n",
        "# initialize weights function\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "# apply model with init weights\n",
        "model.apply(init_weights)\n",
        "\n",
        "# transfer model to device (cuda:0 mean using GPU, xla mean using TPU, otherwise using CPU)\n",
        "model = model.to(device)\n",
        "\n",
        "# Model details\n",
        "model\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Download pretrained weights.\\n# model = PlantModel(num_classes=4)\\nmodel = torchvision.models.resnet18(pretrained=True)\\n\\n# print number of features\\nnum_features = model.fc.in_features\\nprint(num_features)\\n\\n\\n# custome layers\\nmodel.fc = nn.Sequential(\\n    nn.Linear(num_features, 512),\\n    nn.ReLU(),\\n    nn.BatchNorm1d(512),\\n    nn.Dropout(0.5),\\n    \\n    nn.Linear(512, 256),\\n    nn.ReLU(),\\n    nn.BatchNorm1d(256),\\n    nn.Dropout(0.5),\\n    \\n    nn.Linear(256, 4))\\n\\n# initialize weights function\\ndef init_weights(m):\\n    if type(m) == nn.Linear:\\n        torch.nn.init.xavier_uniform_(m.weight)\\n        m.bias.data.fill_(0.01)\\n\\n# apply model with init weights\\nmodel.apply(init_weights)\\n\\n# transfer model to device (cuda:0 mean using GPU, xla mean using TPU, otherwise using CPU)\\nmodel = model.to(device)\\n\\n# Model details\\nmodel\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPbkbUUym_wo"
      },
      "source": [
        "#print(torch.cuda.memory_summary(device=None, abbreviated=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IIsjR2GUU1Z"
      },
      "source": [
        "# Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zdNHyqAdrdt",
        "outputId": "4365b313-3c1d-446b-e2fe-50b447ab5640"
      },
      "source": [
        "submissions = None\n",
        "train_results = []\n",
        "\n",
        "for i_fold, (train_idx, valid_idx) in enumerate(folds.split(df_train, train_y)):\n",
        "    # data preparation phase\n",
        "    print(\"Fold {}/{}\".format(i_fold + 1, N_FOLDS))\n",
        "\n",
        "    valid = df_train.iloc[valid_idx]\n",
        "    valid.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    train = df_train.iloc[train_idx]\n",
        "    train.reset_index(drop=True, inplace=True)    \n",
        "\n",
        "    # data transformation phase\n",
        "    dataset_train = PlantDataset(df=train, transforms=transforms_train)\n",
        "    dataset_valid = PlantDataset(df=valid, transforms=transforms_valid)\n",
        "\n",
        "    # data loader phase\n",
        "    dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, num_workers=4, shuffle=True, pin_memory=True, drop_last=True)\n",
        "    dataloader_valid = DataLoader(dataset_valid, batch_size=BATCH_SIZE, num_workers=4, shuffle=False, pin_memory=True, drop_last=False)\n",
        "\n",
        "\n",
        "    # device = torch.device(\"cuda:0\")    \n",
        "    model = model.to(device)\n",
        "\n",
        "    # optimization phase\n",
        "    criterion = DenseCrossEntropy()\n",
        "\n",
        "    # optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    optimizer = AdamW(model.parameters(), lr = lr, weight_decay = 1e-3)\n",
        "\n",
        "    # lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=[int(N_EPOCHS * 0.5), int(N_EPOCHS * 0.75)], gamma=0.1, last_epoch=-1)\n",
        "    num_train_steps = int(len(dataset_train) / BATCH_SIZE * N_EPOCHS)\n",
        "    lr_scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=len(dataset_train)/BATCH_SIZE*5, num_training_steps=num_train_steps)\n",
        "    \n",
        "    # training in one fold\n",
        "    val_preds, train_fold_results = train_one_fold(i_fold, model, criterion, optimizer, lr_scheduler, dataloader_train, dataloader_valid)\n",
        "    oof_preds[valid_idx, :] = val_preds\n",
        "    \n",
        "    # calculate the results phase\n",
        "    train_results = train_results + train_fold_results\n",
        "\n",
        "    # model evaluation phase\n",
        "    model.eval()\n",
        "    test_preds = None\n",
        "\n",
        "    # looping test dataloader\n",
        "    for step, batch in enumerate(dataloader_test):\n",
        "\n",
        "        images = batch[0].to(device, dtype=torch.float)\n",
        "\n",
        "        # empty torch gradient\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "\n",
        "            if test_preds is None:\n",
        "                test_preds = outputs.data.cpu()\n",
        "            else:\n",
        "                test_preds = torch.cat((test_preds, outputs.data.cpu()), dim=0)\n",
        "    \n",
        "    \n",
        "    # Save predictions per fold\n",
        "    submission_df[['healthy', 'multiple_diseases', 'rust', 'scab']] = torch.softmax(test_preds, dim=1)\n",
        "    submission_df.to_csv('submission_fold_{}.csv'.format(i_fold), index=False)\n",
        "\n",
        "    # logits avg\n",
        "    if submissions is None:\n",
        "        submissions = test_preds / N_FOLDS\n",
        "    else:\n",
        "        submissions += test_preds / N_FOLDS\n",
        "\n",
        "print(\"5-Folds CV score: {:.4f}\".format(roc_auc_score(train_labels, oof_preds, average='macro')))\n",
        "\n",
        "torch.save(model.state_dict(), '5-folds_efficientnet-b5.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1/5\n",
            "  Epoch 1/5\n",
            "  --------------------\n",
            "Fold 1 Epoch 1: train_loss=1.39033429, valid_loss=1.38927542, acc=0.46351661\n",
            "  Epoch 2/5\n",
            "  --------------------\n",
            "Fold 1 Epoch 2: train_loss=0.94588208, valid_loss=1.01016009, acc=0.88227935\n",
            "  Epoch 3/5\n",
            "  --------------------\n",
            "Fold 1 Epoch 3: train_loss=0.61244086, valid_loss=0.47501159, acc=0.96372803\n",
            "  Epoch 4/5\n",
            "  --------------------\n",
            "Fold 1 Epoch 4: train_loss=0.48347866, valid_loss=0.38101518, acc=0.97258272\n",
            "  Epoch 5/5\n",
            "  --------------------\n",
            "Fold 1 Epoch 5: train_loss=0.45059714, valid_loss=0.35878521, acc=0.97257272\n",
            "Fold 2/5\n",
            "  Epoch 1/5\n",
            "  --------------------\n",
            "Fold 2 Epoch 1: train_loss=0.40934049, valid_loss=0.22052174, acc=0.98832166\n",
            "  Epoch 2/5\n",
            "  --------------------\n",
            "Fold 2 Epoch 2: train_loss=0.42048601, valid_loss=0.22041170, acc=0.98958711\n",
            "  Epoch 3/5\n",
            "  --------------------\n",
            "Fold 2 Epoch 3: train_loss=0.41111801, valid_loss=0.20013423, acc=0.98991668\n",
            "  Epoch 4/5\n",
            "  --------------------\n",
            "Fold 2 Epoch 4: train_loss=0.37648395, valid_loss=0.19440735, acc=0.99227398\n",
            "  Epoch 5/5\n",
            "  --------------------\n",
            "Fold 2 Epoch 5: train_loss=0.38173576, valid_loss=0.21576084, acc=0.98910156\n",
            "Fold 3/5\n",
            "  Epoch 1/5\n",
            "  --------------------\n",
            "Fold 3 Epoch 1: train_loss=0.36221578, valid_loss=0.17561844, acc=0.99231172\n",
            "  Epoch 2/5\n",
            "  --------------------\n",
            "Fold 3 Epoch 2: train_loss=0.32955847, valid_loss=0.24583416, acc=0.98658576\n",
            "  Epoch 3/5\n",
            "  --------------------\n",
            "Fold 3 Epoch 3: train_loss=0.33848619, valid_loss=0.16472041, acc=0.99336584\n",
            "  Epoch 4/5\n",
            "  --------------------\n",
            "Fold 3 Epoch 4: train_loss=0.34208597, valid_loss=0.21884800, acc=0.98913678\n",
            "  Epoch 5/5\n",
            "  --------------------\n",
            "Fold 3 Epoch 5: train_loss=0.31841973, valid_loss=0.25308973, acc=0.98694552\n",
            "Fold 4/5\n",
            "  Epoch 1/5\n",
            "  --------------------\n",
            "Fold 4 Epoch 1: train_loss=0.33102658, valid_loss=0.09250025, acc=0.99844272\n",
            "  Epoch 2/5\n",
            "  --------------------\n",
            "Fold 4 Epoch 2: train_loss=0.32655635, valid_loss=0.09538791, acc=0.99853329\n",
            "  Epoch 3/5\n",
            "  --------------------\n",
            "Fold 4 Epoch 3: train_loss=0.30957277, valid_loss=0.09393675, acc=0.99808799\n",
            "  Epoch 4/5\n",
            "  --------------------\n",
            "Fold 4 Epoch 4: train_loss=0.31040291, valid_loss=0.09965505, acc=0.99799742\n",
            "  Epoch 5/5\n",
            "  --------------------\n",
            "Fold 4 Epoch 5: train_loss=0.29735322, valid_loss=0.14312022, acc=0.99505394\n",
            "Fold 5/5\n",
            "  Epoch 1/5\n",
            "  --------------------\n",
            "Fold 5 Epoch 1: train_loss=0.31416369, valid_loss=0.17492049, acc=0.99268154\n",
            "  Epoch 2/5\n",
            "  --------------------\n",
            "Fold 5 Epoch 2: train_loss=0.32029929, valid_loss=0.14625491, acc=0.99500614\n",
            "  Epoch 3/5\n",
            "  --------------------\n",
            "Fold 5 Epoch 3: train_loss=0.31029554, valid_loss=0.12626440, acc=0.99690054\n",
            "  Epoch 4/5\n",
            "  --------------------\n",
            "Fold 5 Epoch 4: train_loss=0.27565095, valid_loss=0.18066774, acc=0.99396208\n",
            "  Epoch 5/5\n",
            "  --------------------\n",
            "Fold 5 Epoch 5: train_loss=0.25620645, valid_loss=0.12465381, acc=0.99710180\n",
            "5-Folds CV score: 0.9608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stmKHCA8S-1g"
      },
      "source": [
        "# Generate training results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "MU1DQ5kd6-vb",
        "outputId": "4c177bb3-bef4-4b80-d005-0bfed2a7d12d"
      },
      "source": [
        "train_results = pd.DataFrame(train_results)\n",
        "train_results.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold</th>\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>valid_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.390334</td>\n",
              "      <td>1.389275</td>\n",
              "      <td>0.463517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.945882</td>\n",
              "      <td>1.010160</td>\n",
              "      <td>0.882279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.612441</td>\n",
              "      <td>0.475012</td>\n",
              "      <td>0.963728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.483479</td>\n",
              "      <td>0.381015</td>\n",
              "      <td>0.972583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.450597</td>\n",
              "      <td>0.358785</td>\n",
              "      <td>0.972573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.409340</td>\n",
              "      <td>0.220522</td>\n",
              "      <td>0.988322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.420486</td>\n",
              "      <td>0.220412</td>\n",
              "      <td>0.989587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.411118</td>\n",
              "      <td>0.200134</td>\n",
              "      <td>0.989917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.376484</td>\n",
              "      <td>0.194407</td>\n",
              "      <td>0.992274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.381736</td>\n",
              "      <td>0.215761</td>\n",
              "      <td>0.989102</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fold  epoch  train_loss  valid_loss  valid_score\n",
              "0     0      0    1.390334    1.389275     0.463517\n",
              "1     0      1    0.945882    1.010160     0.882279\n",
              "2     0      2    0.612441    0.475012     0.963728\n",
              "3     0      3    0.483479    0.381015     0.972583\n",
              "4     0      4    0.450597    0.358785     0.972573\n",
              "5     1      0    0.409340    0.220522     0.988322\n",
              "6     1      1    0.420486    0.220412     0.989587\n",
              "7     1      2    0.411118    0.200134     0.989917\n",
              "8     1      3    0.376484    0.194407     0.992274\n",
              "9     1      4    0.381736    0.215761     0.989102"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kJYVnCW8Ujl"
      },
      "source": [
        "train_results.to_csv('train_result.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VBeUEyxTDWn"
      },
      "source": [
        "# Plotting results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9ZoKkYYTI4A"
      },
      "source": [
        "## Training loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnfrPHuj6dXJ"
      },
      "source": [
        "def show_training_loss(train_result):\n",
        "    plt.figure(figsize=(15,10))\n",
        "    plt.subplot(3,1,1)\n",
        "    train_loss = train_result['train_loss']\n",
        "    plt.plot(train_loss.index, train_loss, label = 'train_loss')\n",
        "    plt.legend()\n",
        "\n",
        "    val_loss = train_result['valid_loss']\n",
        "    plt.plot(val_loss.index, val_loss, label = 'val_loss')\n",
        "    plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "mW4YSl-e6mfv",
        "outputId": "b788896b-c2f2-42eb-a5f2-32c74de6de98"
      },
      "source": [
        "show_training_loss(train_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7HT8D8rTLPp"
      },
      "source": [
        "## Validation score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKDkOr1F6jrl"
      },
      "source": [
        "def show_valid_score(train_result):\n",
        "    plt.figure(figsize=(15,10))\n",
        "    plt.subplot(3,1,1)\n",
        "    valid_score = train_result['valid_score']\n",
        "    plt.plot(valid_score.index, valid_score, label = 'valid_score')\n",
        "    plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "L9aueUU07Bz6",
        "outputId": "8cc9600a-e3e8-42ec-a28b-22708646e453"
      },
      "source": [
        "show_valid_score(train_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "H9ZkK0kr8fEh",
        "outputId": "63ddacf5-337c-4b0a-bd3f-9092a1e5a6cd"
      },
      "source": [
        "submission_df[['healthy', 'multiple_diseases', 'rust', 'scab']] = torch.softmax(submissions, dim=1)\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "submission_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>healthy</th>\n",
              "      <th>multiple_diseases</th>\n",
              "      <th>rust</th>\n",
              "      <th>scab</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Test_0</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.008367</td>\n",
              "      <td>0.991500</td>\n",
              "      <td>0.000026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test_1</td>\n",
              "      <td>0.000306</td>\n",
              "      <td>0.023751</td>\n",
              "      <td>0.975833</td>\n",
              "      <td>0.000110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test_2</td>\n",
              "      <td>0.001112</td>\n",
              "      <td>0.004196</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>0.994611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Test_3</td>\n",
              "      <td>0.998752</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.001108</td>\n",
              "      <td>0.000074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Test_4</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.001075</td>\n",
              "      <td>0.998903</td>\n",
              "      <td>0.000003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_id   healthy  multiple_diseases      rust      scab\n",
              "0   Test_0  0.000107           0.008367  0.991500  0.000026\n",
              "1   Test_1  0.000306           0.023751  0.975833  0.000110\n",
              "2   Test_2  0.001112           0.004196  0.000082  0.994611\n",
              "3   Test_3  0.998752           0.000067  0.001108  0.000074\n",
              "4   Test_4  0.000019           0.001075  0.998903  0.000003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    }
  ]
}